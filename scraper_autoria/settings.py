import os
from dotenv import load_dotenv
from scrapy.utils.request import RequestFingerprinter
import sys
import asyncio
# if sys.platform == 'win32':
#     asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

load_dotenv()

# REQUEST_FINGERPRINTER_IMPLEMENTATION = "2.6"
BOT_NAME = "scraper_autoria"

DATABASE_URL = os.getenv('DATABASE_URL')

SPIDER_MODULES = ["scraper_autoria.spiders"]
NEWSPIDER_MODULE = "scraper_autoria.spiders"

PLAYWRIGHT_BROWSER_TYPE = "firefox"

PLAYWRIGHT_LAUNCH_OPTIONS = {
    "headless": True,          # üõë –ë—Ä–∞—É–∑–µ—Ä –±—É–¥–µ –≤—ñ–¥–∫—Ä–∏–≤–∞—Ç–∏—Å—å —É –≤—ñ–∫–Ω—ñ
    # "slow_mo": 1000,            # üê¢ –ó–∞—Ç—Ä–∏–º–∫–∞ 1—Å –º—ñ–∂ –¥—ñ—è–º–∏ (—â–æ–± –≤–∏ –±–∞—á–∏–ª–∏ –∫–ª—ñ–∫–∏)
    "timeout": 5 * 1000,       # –¢–∞–π–º–∞—É—Ç –∑–∞–ø—É—Å–∫—É
    "args": [
        "--no-sandbox",
        "--disable-gpu",
        "--disable-extensions",
        "--disable-component-extensions-with-background-pages",
    ],
# üëá –¶–ï –í–ê–ñ–õ–ò–í–û –î–õ–Ø FIREFOX: –í–∏–º–∏–∫–∞—î–º–æ –ø—Ä–∞–ø–æ—Ä–µ—Ü—å "–Ø —Ä–æ–±–æ—Ç"
    "firefox_user_prefs": {
        "dom.webdriver.enabled": False,
        "useAutomationExtension": False,
        "browser.cache.disk.enable": False,  # –ù–µ –∫–µ—à—É–≤–∞—Ç–∏ –Ω–∞ –¥–∏—Å–∫ (—à–≤–∏–¥—à–µ)
        "browser.cache.memory.enable": False,
        "permissions.default.image": 2,  # –ë–ª–æ–∫—É–≤–∞–Ω–Ω—è –∫–∞—Ä—Ç–∏–Ω–æ–∫ –Ω–∞ —Ä—ñ–≤–Ω—ñ —Ä—É—à—ñ—è Firefox
        "permissions.default.stylesheet": 2,
    }
}
PLAYWRIGHT_CONTEXT_ARGS = {
    "viewport":{"width":1920, "height":1080},
    "device_scale_factor":1,
    "is_mobile": False,          # üëà –í–∞–∂–ª–∏–≤–æ!
    "has_touch": False,          # üëà –í–∞–∂–ª–∏–≤–æ! AutoRIA –¥–∏–≤–∏—Ç—å—Å—è –Ω–∞ —Ü–µ
    "java_script_enabled": True,
    "locale": "uk-UA",
    "timezone_id": "Europe/Kiev",
    "bypass_csp": True,
    "ignore_https_errors": True,
    "permissions": ["notifications"],
    # "service_workers": "allow", # –ë–ª–æ–∫—É—î–º–æ —Å–µ—Ä–≤—ñ—Å –≤–æ—Ä–∫–µ—Ä–∏ (—á–∞—Å—Ç–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–ª—è —Ñ—ñ–Ω–≥–µ—Ä–ø—Ä–∏–Ω—Ç–∏–Ω–≥—É)
}

ADDONS = {}

SCRAPEOPS_API_KEY = os.getenv('SCRAPEOPS_API_KEY')
PROXY_URL = os.getenv('PROXY_URL')
# SCRAPEOPS_PROXY_ENABLED = True
# SCRAPEOPS_PROXY_SETTINGS = {'country': 'ua'}
SCRAPEOPS_FAKE_USER_AGENT_ENABLED = True
SCRAPEOPS_NUM_RESULTS = 5
PLAYWRIGHT_MAX_CONTEXTS = 4
PLAYWRIGHT_MAX_PAGES_PER_CONTEXT = 4
# Obey robots.txt rules
ROBOTSTXT_OBEY = True

# Configure maximum concurrent requests performed by Scrapy (default: 16)
CONCURRENT_REQUESTS = 6

# Configure a delay for requests for the same website (default: 0)
# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay
# See also autothrottle settings and docs
DOWNLOAD_DELAY = 1
DOWNLOAD_TIMEOUT = 30
RETRY_TIMES = 3
RETRY_HTTP_CODES = [500, 502, 503, 504, 522, 524, 408, 429, 403]

# Enable or disable downloader middlewares
# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html
DOWNLOAD_HANDLERS = {
    "http": "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler",
    "https": "scrapy_playwright.handler.ScrapyPlaywrightDownloadHandler",
}

DOWNLOADER_MIDDLEWARES = {
    # –í–∏–º–∏–∫–∞—î–º–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π UserAgent middleware, —â–æ–± –Ω–µ –∑–∞–≤–∞–∂–∞–≤
    'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,
    # 1. –°–ø–æ—á–∞—Ç–∫—É —Å—Ç–∞–≤–∏–º–æ –ø—Ä–æ–∫—Å—ñ (–≤–∞—à —ñ—Å–Ω—É—é—á–∏–π)
    'scraper_autoria.middlewares.ProxyMiddleware': 350,
    # 2. –ü–æ—Ç—ñ–º ScrapeOps –≥–µ–Ω–µ—Ä—É—î –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞ UA
    'scraper_autoria.middlewares.ScrapeOpsFakeUserAgentMiddleware': 370,
    'scraper_autoria.middlewares.ScrapeOpsFakeBrowserHeaderAgentMiddleware': 380,
    # 3. –í–ê–ñ–õ–ò–í–û: –ù–∞—à –Ω–æ–≤–∏–π middleware –º–∞—î –π—Ç–∏ –ü–Ü–°–õ–Ø ScrapeOps, –∞–ª–µ –î–û —Ö–µ–Ω–¥–ª–µ—Ä–∞
    'scraper_autoria.middlewares.PlaywrightContextMiddleware': 400
}

# Configure item pipelines
# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html
ITEM_PIPELINES = {
    "scraper_autoria.pipelines.PostgreSQLPipeline": 300
}

# Enable and configure the AutoThrottle extension (disabled by default)
# See https://docs.scrapy.org/en/latest/topics/autothrottle.html
AUTOTHROTTLE_ENABLED = True

# Enable and configure HTTP caching (disabled by default)
# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings
HTTPCACHE_ENABLED = False
TWISTED_REACTOR = "twisted.internet.asyncioreactor.AsyncioSelectorReactor"

# Set settings whose default value is deprecated to a future-proof value
FEED_EXPORT_ENCODING = "utf-8"

PLAYWRIGHT_ABORT_REQUEST = lambda req: (
    req.resource_type in {"image", "media", "other"}
)
# –†—ñ–≤–µ–Ω—å –ª–æ–≥—É–≤–∞–Ω–Ω—è –¥–ª—è Scrapy
LOG_LEVEL = 'INFO'

# –í–∏–º–∏–∫–∞—î–º–æ/—Ñ—ñ–ª—å—Ç—Ä—É—î–º–æ —à—É–º–Ω—ñ –ª–æ–≥–∏ –±—ñ–±–ª—ñ–æ—Ç–µ–∫
import logging
logging.getLogger('scrapy_playwright').setLevel(logging.WARNING)
logging.getLogger('playwright').setLevel(logging.WARNING)
logging.getLogger('asyncio').setLevel(logging.WARNING)

# The download delay setting will honor only one of:
CONCURRENT_REQUESTS_PER_DOMAIN = 4
CONCURRENT_REQUESTS_PER_IP = 1

COOKIES_ENABLED = False